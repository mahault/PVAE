{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPClE5Ie/vmHiA8ux1GfWTv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahault/PVAE/blob/main/PVAE\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PVAE model"
      ],
      "metadata": {
        "id": "np_Mqbiu67_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class PVAE(nn.Module):\n",
        "    def __init__(self, input_dim, latent_dim):\n",
        "        super(PVAE, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 400)\n",
        "        self.fc21 = nn.Linear(400, latent_dim)  # Rate (lambda)\n",
        "        self.fc3 = nn.Linear(latent_dim, 400)\n",
        "        self.fc4 = nn.Linear(400, input_dim)\n",
        "\n",
        "    def encode(self, x):\n",
        "        h1 = F.relu(self.fc1(x))\n",
        "        return F.softplus(self.fc21(h1))  # Ensures positive rates\n",
        "\n",
        "    def reparameterize(self, rate):\n",
        "        # Poisson reparameterization trick\n",
        "        eps = torch.randn_like(rate)\n",
        "        rate = torch.clamp(rate + eps * torch.sqrt(rate), min=1e-10)  # Ensure non-negative rates\n",
        "        return torch.poisson(rate)\n",
        "\n",
        "    def decode(self, z):\n",
        "        h3 = F.relu(self.fc3(z))\n",
        "        return torch.sigmoid(self.fc4(h3))\n",
        "\n",
        "    def forward(self, x):\n",
        "        rate = self.encode(x)\n",
        "        z = self.reparameterize(rate)\n",
        "        return self.decode(z), rate\n",
        "\n",
        "def loss_function(recon_x, x, rate):\n",
        "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
        "    KL = torch.sum(rate - torch.log(rate) + rate * torch.log(rate) - rate)\n",
        "    return BCE + KL\n"
      ],
      "metadata": {
        "id": "ipMFle5266u5"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate images"
      ],
      "metadata": {
        "id": "sdRtaEts6W7j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rc0kUVVn6R3U",
        "outputId": "6aa5b30a-a2f4-472c-aa1a-39df0efa6ff5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset created and saved as shapes_dataset.npz\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "def create_shape_image(shape, size=28):\n",
        "    image = Image.new('L', (size, size), 0)  # Create a blank image\n",
        "    draw = ImageDraw.Draw(image)\n",
        "\n",
        "    if shape == 'circle':\n",
        "        draw.ellipse((4, 4, size-4, size-4), fill=255)\n",
        "    elif shape == 'square':\n",
        "        draw.rectangle((4, 4, size-4, size-4), fill=255)\n",
        "    elif shape == 'triangle':\n",
        "        draw.polygon([(size/2, 4), (4, size-4), (size-4, size-4)], fill=255)\n",
        "\n",
        "    return np.array(image)\n",
        "\n",
        "def create_dataset(num_samples=1000, size=28):\n",
        "    shapes = ['circle', 'square', 'triangle']\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        shape = np.random.choice(shapes)\n",
        "        image = create_shape_image(shape, size)\n",
        "        images.append(image)\n",
        "        labels.append(shapes.index(shape))\n",
        "\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    # Normalize pixel values to [0, 1]\n",
        "    images = images / 255.0\n",
        "\n",
        "    return train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create the dataset\n",
        "X_train, X_test, y_train, y_test = create_dataset(num_samples=100000, size=28)\n",
        "\n",
        "# Save the dataset\n",
        "np.savez('shapes_dataset.npz', X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)\n",
        "\n",
        "print(\"Dataset created and saved as shapes_dataset.npz\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading and Using the Dataset"
      ],
      "metadata": {
        "id": "ckJFc9MU6faN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Load the dataset\n",
        "data = np.load('shapes_dataset.npz')\n",
        "X_train, X_test = data['X_train'], data['X_test']\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "# Create DataLoader\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(TensorDataset(X_train_tensor, X_train_tensor), batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(X_test_tensor, X_test_tensor), batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Verify the DataLoader\n",
        "for batch in train_loader:\n",
        "    print(batch[0].shape)  # Should print: torch.Size([batch_size, 1, 28, 28])\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2b7BmkC6ZLY",
        "outputId": "5982244d-766b-4bb2-b5b7-52449bf58f60"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running P-VAE on the Dataset"
      ],
      "metadata": {
        "id": "v82r4QrF6jo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Initialize the model, optimizer, and loss function\n",
        "input_dim = 28 * 28  # Flatten the images\n",
        "latent_dim = 10\n",
        "model = PVAE(input_dim=input_dim, latent_dim=latent_dim)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for batch_idx, (data, _) in enumerate(train_loader):\n",
        "        data = data.view(-1, input_dim)\n",
        "        optimizer.zero_grad()\n",
        "        recon_batch, rate = model(data)\n",
        "        loss = loss_function(recon_batch, data, rate)\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch {epoch+1}, Loss: {train_loss / len(train_loader.dataset)}')\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "test_loss = 0\n",
        "with torch.no_grad():\n",
        "    for data, _ in test_loader:\n",
        "        data = data.view(-1, input_dim)\n",
        "        recon_batch, rate = model(data)\n",
        "        test_loss += loss_function(recon_batch, data, rate).item()\n",
        "\n",
        "print(f'Test Loss: {test_loss / len(test_loader.dataset)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZSaMHVq6igs",
        "outputId": "25594637-3829-4388-cabc-cf940a93c01e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 163.73977801513672\n",
            "Epoch 2, Loss: 159.98922192382813\n",
            "Epoch 3, Loss: 159.5239967529297\n",
            "Epoch 4, Loss: 159.38616217041016\n",
            "Epoch 5, Loss: 159.2917764892578\n",
            "Epoch 6, Loss: 159.24564692382813\n",
            "Epoch 7, Loss: 159.2196879638672\n",
            "Epoch 8, Loss: 159.1994489013672\n",
            "Epoch 9, Loss: 159.2017956665039\n",
            "Epoch 10, Loss: 159.18199119873046\n",
            "Epoch 11, Loss: 159.1787465209961\n",
            "Epoch 12, Loss: 159.15594024658202\n",
            "Epoch 13, Loss: 159.158901953125\n",
            "Epoch 14, Loss: 159.1691462890625\n",
            "Epoch 15, Loss: 159.17140622558594\n",
            "Epoch 16, Loss: 159.13776899414063\n",
            "Epoch 17, Loss: 159.16743734130858\n",
            "Epoch 18, Loss: 159.16039682617188\n",
            "Epoch 19, Loss: 159.15671923828126\n",
            "Epoch 20, Loss: 159.16064890136718\n",
            "Epoch 21, Loss: 159.16218267822265\n",
            "Epoch 22, Loss: 159.14670158691408\n",
            "Epoch 23, Loss: 159.14755837402345\n",
            "Epoch 24, Loss: 159.14663708496093\n",
            "Epoch 25, Loss: 159.13332612304688\n",
            "Epoch 26, Loss: 159.14984946289061\n",
            "Epoch 27, Loss: 159.14359639892578\n",
            "Epoch 28, Loss: 159.12746208496094\n",
            "Epoch 29, Loss: 159.14003862304688\n",
            "Epoch 30, Loss: 159.1321266479492\n",
            "Epoch 31, Loss: 159.13428353271485\n",
            "Epoch 32, Loss: 159.14038237304686\n",
            "Epoch 33, Loss: 159.13511066894532\n",
            "Epoch 34, Loss: 159.14749256591796\n",
            "Epoch 35, Loss: 159.1401453125\n",
            "Epoch 36, Loss: 159.1422217163086\n",
            "Epoch 37, Loss: 159.13552178955078\n",
            "Epoch 38, Loss: 159.1261210205078\n",
            "Epoch 39, Loss: 159.14381000976562\n",
            "Epoch 40, Loss: 159.1381697998047\n",
            "Epoch 41, Loss: 159.13282841796874\n",
            "Epoch 42, Loss: 159.1245523071289\n",
            "Epoch 43, Loss: 159.1295245727539\n",
            "Epoch 44, Loss: 159.12434619140626\n",
            "Epoch 45, Loss: 159.12965659179687\n",
            "Epoch 46, Loss: 159.13288612060546\n",
            "Epoch 47, Loss: 159.1217750366211\n",
            "Epoch 48, Loss: 159.13149770507812\n",
            "Epoch 49, Loss: 159.12544875488283\n",
            "Epoch 50, Loss: 159.12631634521483\n",
            "Epoch 51, Loss: 159.13174478759765\n",
            "Epoch 52, Loss: 159.11697447509766\n",
            "Epoch 53, Loss: 159.1275352294922\n",
            "Epoch 54, Loss: 159.12112895507812\n",
            "Epoch 55, Loss: 159.12364025878907\n",
            "Epoch 56, Loss: 159.13031588134766\n",
            "Epoch 57, Loss: 159.12391551513673\n",
            "Epoch 58, Loss: 159.1205216430664\n",
            "Epoch 59, Loss: 159.1210704223633\n",
            "Epoch 60, Loss: 159.12842436523437\n",
            "Epoch 61, Loss: 159.11535021972657\n",
            "Epoch 62, Loss: 159.1244695678711\n",
            "Epoch 63, Loss: 159.1139456665039\n",
            "Epoch 64, Loss: 159.1281362915039\n",
            "Epoch 65, Loss: 159.1199584838867\n",
            "Epoch 66, Loss: 159.12320833740233\n",
            "Epoch 67, Loss: 159.12119548339842\n",
            "Epoch 68, Loss: 159.10736361083985\n",
            "Epoch 69, Loss: 159.1130689819336\n",
            "Epoch 70, Loss: 159.11935615234376\n",
            "Epoch 71, Loss: 159.11671368408204\n",
            "Epoch 72, Loss: 159.1093617919922\n",
            "Epoch 73, Loss: 159.11387302246095\n",
            "Epoch 74, Loss: 159.12183845214844\n",
            "Epoch 75, Loss: 159.1196484008789\n",
            "Epoch 76, Loss: 159.11619174804687\n",
            "Epoch 77, Loss: 159.1167540649414\n",
            "Epoch 78, Loss: 159.1165412963867\n",
            "Epoch 79, Loss: 159.1114775390625\n",
            "Epoch 80, Loss: 159.1222064941406\n",
            "Epoch 81, Loss: 159.11435373535156\n",
            "Epoch 82, Loss: 159.11199794921876\n",
            "Epoch 83, Loss: 159.12032196044922\n",
            "Epoch 84, Loss: 159.11337468261718\n",
            "Epoch 85, Loss: 159.11954315185548\n",
            "Epoch 86, Loss: 159.1158955078125\n",
            "Epoch 87, Loss: 159.1173551879883\n",
            "Epoch 88, Loss: 159.11077252197265\n",
            "Epoch 89, Loss: 159.11644841308595\n",
            "Epoch 90, Loss: 159.10964807128906\n",
            "Epoch 91, Loss: 159.11690557861328\n",
            "Epoch 92, Loss: 159.11806513671874\n",
            "Epoch 93, Loss: 159.11511353759767\n",
            "Epoch 94, Loss: 159.1062655883789\n",
            "Epoch 95, Loss: 159.12002501220704\n",
            "Epoch 96, Loss: 159.11761064453125\n",
            "Epoch 97, Loss: 159.10503316650392\n",
            "Epoch 98, Loss: 159.11915756835938\n",
            "Epoch 99, Loss: 159.11654498291017\n",
            "Epoch 100, Loss: 159.11392412109376\n",
            "Test Loss: 158.93765849609375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JWtPT0ke6oHP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the results"
      ],
      "metadata": {
        "id": "gUJJBTbl-6up"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_reconstructions(model, data_loader, num_images=10):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        data_iter = iter(data_loader)\n",
        "        original_images, _ = next(data_iter)\n",
        "        original_images = original_images[:num_images]\n",
        "\n",
        "        input_images = original_images.view(-1, 28*28)\n",
        "        reconstructions, _ = model(input_images)\n",
        "        reconstructions = reconstructions.view(-1, 1, 28, 28)\n",
        "\n",
        "        # Plot original and reconstructed images\n",
        "        fig, axes = plt.subplots(2, num_images, figsize=(num_images * 2, 4))\n",
        "        for i in range(num_images):\n",
        "            axes[0, i].imshow(original_images[i].squeeze(), cmap='gray')\n",
        "            axes[0, i].set_title(\"Original\")\n",
        "            axes[0, i].axis('off')\n",
        "\n",
        "            axes[1, i].imshow(reconstructions[i].squeeze(), cmap='gray')\n",
        "            axes[1, i].set_title(\"Reconstructed\")\n",
        "            axes[1, i].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Load the dataset\n",
        "data = np.load('shapes_dataset.npz')\n",
        "X_train, X_test = data['X_train'], data['X_test']\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "# Create DataLoader\n",
        "batch_size = 64\n",
        "test_loader = DataLoader(TensorDataset(X_test_tensor, X_test_tensor), batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Plot reconstructions\n",
        "plot_reconstructions(model, test_loader, num_images=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "GPlOJgYf-7w8",
        "outputId": "04bcbb06-28b1-4caa-9a35-abe543b3f3f3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x400 with 20 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hebPQLzV-8da"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}